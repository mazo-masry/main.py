import os
import requests
from bs4 import BeautifulSoup
import logging
from telegram import Update, ReplyKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)

# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù† Ù…ØªØºÙŠØ±Ø§Øª Ø¨ÙŠØ¦Ø© Railway
TOKEN = os.getenv("BOT_TOKEN")
EXPIRED_COOKIE = os.getenv("EXPIRED_COOKIE") # ØªØ£ÙƒØ¯ Ù…Ù† ØªØ­Ø¯ÙŠØ«Ù‡ Ù…Ù† Ø§Ù„Ù…ØªØµÙØ­
ADMIN_ID = 665829780
allowed_users = {ADMIN_ID}

async def fetch_expired_data():
    url = "https://www.expireddomains.net/expired-domains/"
    
    # Ù‡Ø°Ù‡ Ø§Ù„ØªØ±ÙˆÙŠØ³Ø§Øª ØªØ¬Ø¹Ù„ Ø§Ù„Ø·Ù„Ø¨ ÙŠØ¨Ø¯Ùˆ ÙƒØ£Ù†Ù‡ Ù…Ù† Ù…ØªØµÙØ­ Ø­Ù‚ÙŠÙ‚ÙŠ
    headers = {
        'authority': 'www.expireddomains.net',
        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'accept-language': 'en-US,en;q=0.9,ar;q=0.8',
        'cache-control': 'max-age=0',
        'cookie': EXPIRED_COOKIE,
        'user-agent': 'Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Mobile Safari/537.36',
        'sec-ch-ua': '"Google Chrome";v="119", "Chromium";v="119", "Not?A_Brand";v="24"',
        'sec-fetch-site': 'none',
        'sec-fetch-mode': 'navigate',
        'sec-fetch-user': '?1',
        'sec-fetch-dest': 'document',
    }

    try:
        response = requests.get(url, headers=headers, timeout=15)
        
        # Ø¥Ø°Ø§ Ø£Ø¹Ø·Ù‰ Ø§Ù„Ù…ÙˆÙ‚Ø¹ 403 Ø£Ùˆ 429 ÙÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø­Ø¸Ø± IP Ø£Ùˆ Cookie
        if response.status_code == 403:
            return "ğŸš« **Ø®Ø·Ø£ 403:** Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§ÙƒØªØ´Ù Ø£Ù†Ùƒ Ø¨ÙˆØª. ÙŠØ±Ø¬Ù‰ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù€ Cookie Ù…Ù† Ø§Ù„Ù…ØªØµÙØ­ Ø§Ù„Ø¢Ù†."
            
        soup = BeautifulSoup(response.text, 'html.parser')
        table = soup.find('table', {'class': 'listing'})
        
        if not table:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø·Ø¨Ø§Ø¹Ø© Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙÙŠ Ø§Ù„Ù€ Logs Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø³Ø¨Ø¨
            logging.warning(f"Response snippet: {response.text[:200]}")
            return "âš ï¸ Ù„Ù… ÙŠØ¸Ù‡Ø± Ø§Ù„Ø¬Ø¯ÙˆÙ„. ØºØ§Ù„Ø¨Ø§Ù‹ ØªØ­ØªØ§Ø¬ Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙÙŠ Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙˆÙ†Ø³Ø® Ø§Ù„Ù€ Cookie Ø§Ù„Ø¬Ø¯ÙŠØ¯."

        rows = table.find_all('tr')[1:]
        report = "ğŸ’ **Ø±Ø§Ø¯Ø§Ø± Ø§Ù„Ù„Ù‚Ø·Ø§Øª Ø§Ù„Ù‚ØµÙŠØ±Ø© (Ù…Ø­Ø¯Ø«):**\n\n"
        found = False
        
        for row in rows[:50]:
            cols = row.find_all('td')
            if len(cols) > 0:
                domain = cols[0].get_text(strip=True)
                # ÙÙ„ØªØ± Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø±Ø¨Ø§Ø¹ÙŠØ© Ø§Ù„Ù†Ù‚ÙŠØ©
                name_only = domain.split('.')[0]
                if len(name_only) <= 4 and name_only.isalpha():
                    bl = cols[1].get_text(strip=True)
                    report += f"âœ… **Ù„Ù‚Ø·Ø©:** `{domain}`\nğŸ“Š Ø¨Ø§ÙƒÙ„ÙŠÙ†Ùƒ: {bl}\n\n"
                    found = True
        
        return report if found else "ğŸ” Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù„Ù‚Ø·Ø§Øª Ø±Ø¨Ø§Ø¹ÙŠØ© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹."

    except Exception as e:
        return f"âŒ Ø®Ø·Ø£ ÙÙ†ÙŠ: {str(e)}"

# ... (Ø¨Ø§Ù‚ÙŠ Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© ÙƒÙ…Ø§ Ù‡ÙŠ ÙÙŠ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø§Ù„Ø³Ø§Ø¨Ù‚) ...
